{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with the following two lines to import tensorflow and MNIST dataset under the Keras API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise and check data samples with MatPLotLib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f90b09d95d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "image_index = 7777 # You may select anything up to 60,000\n",
    "print(y_train[image_index]) # The label is 8\n",
    "plt.imshow(x_train[image_index], cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get shape of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape and normalise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "Number of images in x_train 60000\n",
      "Number of images in x_test 10000\n"
     ]
    }
   ],
   "source": [
    "# Reshaping the array to 4-dims so that it can work with the Keras API\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "input_shape = (28, 28, 1)\n",
    "# Making sure that the values are float so that we can get decimal points after division\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "# Normalizing the RGB codes by dividing it to the max RGB value.\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('Number of images in x_train', x_train.shape[0])\n",
    "print('Number of images in x_test', x_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required Keras modules containing model and layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "# Creating a Sequential Model and adding the layers\n",
    "model = Sequential()\n",
    "model.add(Conv2D(28, kernel_size=(3,3), input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten()) # Flattening the 2D arrays for fully connected layers\n",
    "model.add(Dense(128, activation=tf.nn.relu))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10,activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling and Fitting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 25s 421us/sample - loss: 0.0683 - accuracy: 0.9790\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 25s 424us/sample - loss: 0.0474 - accuracy: 0.9849\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f908c579150>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.fit(x=x_train,y=y_train, epochs=2) #epochs=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model\n",
    "Finally, you can evaluate the trained model with x_test and y_test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 162us/sample - loss: 0.0580 - accuracy: 0.9824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.058013553178950676, 0.9824]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
